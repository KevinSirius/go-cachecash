// +build sqlboiler_test

// Code generated by SQLBoiler (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"bytes"
	"context"
	"reflect"
	"testing"

	"github.com/volatiletech/sqlboiler/boil"
	"github.com/volatiletech/sqlboiler/queries"
	"github.com/volatiletech/sqlboiler/randomize"
	"github.com/volatiletech/sqlboiler/strmangle"
)

var (
	// Relationships sometimes use the reflection helper queries.Equal/queries.Assign
	// so force a package dependency in case they don't.
	_ = queries.Equal
)

func testCaches(t *testing.T) {
	t.Parallel()

	query := Caches()

	if query.Query == nil {
		t.Error("expected a query, got nothing")
	}
}

func testCachesDelete(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if rowsAff, err := o.Delete(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testCachesQueryDeleteAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if rowsAff, err := Caches().DeleteAll(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testCachesSliceDeleteAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice := CacheSlice{o}

	if rowsAff, err := slice.DeleteAll(ctx, tx); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only have deleted one row, but affected:", rowsAff)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 0 {
		t.Error("want zero records, got:", count)
	}
}

func testCachesExists(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	e, err := CacheExists(ctx, tx, o.ID)
	if err != nil {
		t.Errorf("Unable to check if Cache exists: %s", err)
	}
	if !e {
		t.Errorf("Expected CacheExists to return true, but got false.")
	}
}

func testCachesFind(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	cacheFound, err := FindCache(ctx, tx, o.ID)
	if err != nil {
		t.Error(err)
	}

	if cacheFound == nil {
		t.Error("want a record, got nil")
	}
}

func testCachesBind(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if err = Caches().Bind(ctx, tx, o); err != nil {
		t.Error(err)
	}
}

func testCachesOne(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if x, err := Caches().One(ctx, tx); err != nil {
		t.Error(err)
	} else if x == nil {
		t.Error("expected to get a non nil record")
	}
}

func testCachesAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	cacheOne := &Cache{}
	cacheTwo := &Cache{}
	if err = randomize.Struct(seed, cacheOne, cacheDBTypes, false, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}
	if err = randomize.Struct(seed, cacheTwo, cacheDBTypes, false, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = cacheOne.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}
	if err = cacheTwo.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice, err := Caches().All(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if len(slice) != 2 {
		t.Error("want 2 records, got:", len(slice))
	}
}

func testCachesCount(t *testing.T) {
	t.Parallel()

	var err error
	seed := randomize.NewSeed()
	cacheOne := &Cache{}
	cacheTwo := &Cache{}
	if err = randomize.Struct(seed, cacheOne, cacheDBTypes, false, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}
	if err = randomize.Struct(seed, cacheTwo, cacheDBTypes, false, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = cacheOne.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}
	if err = cacheTwo.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 2 {
		t.Error("want 2 records, got:", count)
	}
}

func cacheBeforeInsertHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheAfterInsertHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheAfterSelectHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheBeforeUpdateHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheAfterUpdateHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheBeforeDeleteHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheAfterDeleteHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheBeforeUpsertHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func cacheAfterUpsertHook(ctx context.Context, e boil.ContextExecutor, o *Cache) error {
	*o = Cache{}
	return nil
}

func testCachesHooks(t *testing.T) {
	t.Parallel()

	var err error

	ctx := context.Background()
	empty := &Cache{}
	o := &Cache{}

	seed := randomize.NewSeed()
	if err = randomize.Struct(seed, o, cacheDBTypes, false); err != nil {
		t.Errorf("Unable to randomize Cache object: %s", err)
	}

	AddCacheHook(boil.BeforeInsertHook, cacheBeforeInsertHook)
	if err = o.doBeforeInsertHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doBeforeInsertHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected BeforeInsertHook function to empty object, but got: %#v", o)
	}
	cacheBeforeInsertHooks = []CacheHook{}

	AddCacheHook(boil.AfterInsertHook, cacheAfterInsertHook)
	if err = o.doAfterInsertHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doAfterInsertHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected AfterInsertHook function to empty object, but got: %#v", o)
	}
	cacheAfterInsertHooks = []CacheHook{}

	AddCacheHook(boil.AfterSelectHook, cacheAfterSelectHook)
	if err = o.doAfterSelectHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doAfterSelectHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected AfterSelectHook function to empty object, but got: %#v", o)
	}
	cacheAfterSelectHooks = []CacheHook{}

	AddCacheHook(boil.BeforeUpdateHook, cacheBeforeUpdateHook)
	if err = o.doBeforeUpdateHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doBeforeUpdateHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected BeforeUpdateHook function to empty object, but got: %#v", o)
	}
	cacheBeforeUpdateHooks = []CacheHook{}

	AddCacheHook(boil.AfterUpdateHook, cacheAfterUpdateHook)
	if err = o.doAfterUpdateHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doAfterUpdateHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected AfterUpdateHook function to empty object, but got: %#v", o)
	}
	cacheAfterUpdateHooks = []CacheHook{}

	AddCacheHook(boil.BeforeDeleteHook, cacheBeforeDeleteHook)
	if err = o.doBeforeDeleteHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doBeforeDeleteHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected BeforeDeleteHook function to empty object, but got: %#v", o)
	}
	cacheBeforeDeleteHooks = []CacheHook{}

	AddCacheHook(boil.AfterDeleteHook, cacheAfterDeleteHook)
	if err = o.doAfterDeleteHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doAfterDeleteHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected AfterDeleteHook function to empty object, but got: %#v", o)
	}
	cacheAfterDeleteHooks = []CacheHook{}

	AddCacheHook(boil.BeforeUpsertHook, cacheBeforeUpsertHook)
	if err = o.doBeforeUpsertHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doBeforeUpsertHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected BeforeUpsertHook function to empty object, but got: %#v", o)
	}
	cacheBeforeUpsertHooks = []CacheHook{}

	AddCacheHook(boil.AfterUpsertHook, cacheAfterUpsertHook)
	if err = o.doAfterUpsertHooks(ctx, nil); err != nil {
		t.Errorf("Unable to execute doAfterUpsertHooks: %s", err)
	}
	if !reflect.DeepEqual(o, empty) {
		t.Errorf("Expected AfterUpsertHook function to empty object, but got: %#v", o)
	}
	cacheAfterUpsertHooks = []CacheHook{}
}

func testCachesInsert(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}
}

func testCachesInsertWhitelist(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Whitelist(cacheColumnsWithoutDefault...)); err != nil {
		t.Error(err)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}
}

func testCacheToManyEscrowCaches(t *testing.T) {
	var err error
	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()

	var a Cache
	var b, c EscrowCache

	seed := randomize.NewSeed()
	if err = randomize.Struct(seed, &a, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	if err := a.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	if err = randomize.Struct(seed, &b, escrowCacheDBTypes, false, escrowCacheColumnsWithDefault...); err != nil {
		t.Fatal(err)
	}
	if err = randomize.Struct(seed, &c, escrowCacheDBTypes, false, escrowCacheColumnsWithDefault...); err != nil {
		t.Fatal(err)
	}

	b.CacheID = a.ID
	c.CacheID = a.ID

	if err = b.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}
	if err = c.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	check, err := a.EscrowCaches().All(ctx, tx)
	if err != nil {
		t.Fatal(err)
	}

	bFound, cFound := false, false
	for _, v := range check {
		if v.CacheID == b.CacheID {
			bFound = true
		}
		if v.CacheID == c.CacheID {
			cFound = true
		}
	}

	if !bFound {
		t.Error("expected to find b")
	}
	if !cFound {
		t.Error("expected to find c")
	}

	slice := CacheSlice{&a}
	if err = a.L.LoadEscrowCaches(ctx, tx, false, (*[]*Cache)(&slice), nil); err != nil {
		t.Fatal(err)
	}
	if got := len(a.R.EscrowCaches); got != 2 {
		t.Error("number of eager loaded records wrong, got:", got)
	}

	a.R.EscrowCaches = nil
	if err = a.L.LoadEscrowCaches(ctx, tx, true, &a, nil); err != nil {
		t.Fatal(err)
	}
	if got := len(a.R.EscrowCaches); got != 2 {
		t.Error("number of eager loaded records wrong, got:", got)
	}

	if t.Failed() {
		t.Logf("%#v", check)
	}
}

func testCacheToManyAddOpEscrowCaches(t *testing.T) {
	var err error

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()

	var a Cache
	var b, c, d, e EscrowCache

	seed := randomize.NewSeed()
	if err = randomize.Struct(seed, &a, cacheDBTypes, false, strmangle.SetComplement(cachePrimaryKeyColumns, cacheColumnsWithoutDefault)...); err != nil {
		t.Fatal(err)
	}
	foreigners := []*EscrowCache{&b, &c, &d, &e}
	for _, x := range foreigners {
		if err = randomize.Struct(seed, x, escrowCacheDBTypes, false, strmangle.SetComplement(escrowCachePrimaryKeyColumns, escrowCacheColumnsWithoutDefault)...); err != nil {
			t.Fatal(err)
		}
	}

	if err := a.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}
	if err = b.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}
	if err = c.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Fatal(err)
	}

	foreignersSplitByInsertion := [][]*EscrowCache{
		{&b, &c},
		{&d, &e},
	}

	for i, x := range foreignersSplitByInsertion {
		err = a.AddEscrowCaches(ctx, tx, i != 0, x...)
		if err != nil {
			t.Fatal(err)
		}

		first := x[0]
		second := x[1]

		if a.ID != first.CacheID {
			t.Error("foreign key was wrong value", a.ID, first.CacheID)
		}
		if a.ID != second.CacheID {
			t.Error("foreign key was wrong value", a.ID, second.CacheID)
		}

		if first.R.Cache != &a {
			t.Error("relationship was not added properly to the foreign slice")
		}
		if second.R.Cache != &a {
			t.Error("relationship was not added properly to the foreign slice")
		}

		if a.R.EscrowCaches[i*2] != first {
			t.Error("relationship struct slice not set to correct value")
		}
		if a.R.EscrowCaches[i*2+1] != second {
			t.Error("relationship struct slice not set to correct value")
		}

		count, err := a.EscrowCaches().Count(ctx, tx)
		if err != nil {
			t.Fatal(err)
		}
		if want := int64((i + 1) * 2); count != want {
			t.Error("want", want, "got", count)
		}
	}
}

func testCachesReload(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	if err = o.Reload(ctx, tx); err != nil {
		t.Error(err)
	}
}

func testCachesReloadAll(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice := CacheSlice{o}

	if err = slice.ReloadAll(ctx, tx); err != nil {
		t.Error(err)
	}
}

func testCachesSelect(t *testing.T) {
	t.Parallel()

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	slice, err := Caches().All(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if len(slice) != 1 {
		t.Error("want one record, got:", len(slice))
	}
}

var (
	cacheDBTypes = map[string]string{`ID`: `integer`, `PublicKey`: `bytea`, `Inetaddr`: `bytea`, `Port`: `integer`}
	_            = bytes.MinRead
)

func testCachesUpdate(t *testing.T) {
	t.Parallel()

	if 0 == len(cachePrimaryKeyColumns) {
		t.Skip("Skipping table with no primary key columns")
	}
	if len(cacheColumns) == len(cachePrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}

	if err = randomize.Struct(seed, o, cacheDBTypes, true, cachePrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	if rowsAff, err := o.Update(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("should only affect one row but affected", rowsAff)
	}
}

func testCachesSliceUpdateAll(t *testing.T) {
	t.Parallel()

	if len(cacheColumns) == len(cachePrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	o := &Cache{}
	if err = randomize.Struct(seed, o, cacheDBTypes, true, cacheColumnsWithDefault...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Insert(ctx, tx, boil.Infer()); err != nil {
		t.Error(err)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}

	if count != 1 {
		t.Error("want one record, got:", count)
	}

	if err = randomize.Struct(seed, o, cacheDBTypes, true, cachePrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	// Remove Primary keys and unique columns from what we plan to update
	var fields []string
	if strmangle.StringSliceMatch(cacheColumns, cachePrimaryKeyColumns) {
		fields = cacheColumns
	} else {
		fields = strmangle.SetComplement(
			cacheColumns,
			cachePrimaryKeyColumns,
		)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	typ := reflect.TypeOf(o).Elem()
	n := typ.NumField()

	updateMap := M{}
	for _, col := range fields {
		for i := 0; i < n; i++ {
			f := typ.Field(i)
			if f.Tag.Get("boil") == col {
				updateMap[col] = value.Field(i).Interface()
			}
		}
	}

	slice := CacheSlice{o}
	if rowsAff, err := slice.UpdateAll(ctx, tx, updateMap); err != nil {
		t.Error(err)
	} else if rowsAff != 1 {
		t.Error("wanted one record updated but got", rowsAff)
	}
}

func testCachesUpsert(t *testing.T) {
	t.Parallel()

	if len(cacheColumns) == len(cachePrimaryKeyColumns) {
		t.Skip("Skipping table with only primary key columns")
	}

	seed := randomize.NewSeed()
	var err error
	// Attempt the INSERT side of an UPSERT
	o := Cache{}
	if err = randomize.Struct(seed, &o, cacheDBTypes, true); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	ctx := context.Background()
	tx := MustTx(boil.BeginTx(ctx, nil))
	defer func() { _ = tx.Rollback() }()
	if err = o.Upsert(ctx, tx, false, nil, boil.Infer(), boil.Infer()); err != nil {
		t.Errorf("Unable to upsert Cache: %s", err)
	}

	count, err := Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}
	if count != 1 {
		t.Error("want one record, got:", count)
	}

	// Attempt the UPDATE side of an UPSERT
	if err = randomize.Struct(seed, &o, cacheDBTypes, false, cachePrimaryKeyColumns...); err != nil {
		t.Errorf("Unable to randomize Cache struct: %s", err)
	}

	if err = o.Upsert(ctx, tx, true, nil, boil.Infer(), boil.Infer()); err != nil {
		t.Errorf("Unable to upsert Cache: %s", err)
	}

	count, err = Caches().Count(ctx, tx)
	if err != nil {
		t.Error(err)
	}
	if count != 1 {
		t.Error("want one record, got:", count)
	}
}
